<!DOCTYPE html> <html> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>IV. ASSISTED TELEOPERATION | Humanoid Teleoperation</title> <meta name="author" content="Humanoid Teleoperation "> <meta name="description" content="Teleoperation of Humanoid Robots: A Survey "> <meta name="keywords" content="score functions, score-based methods, diffusion"> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700%7CRoboto+Slab:100,300,400,500,700%7CMaterial+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="none" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%88%87&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://humanoid-teleoperation.github.io/4-assisted-teleop/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js"></script> <script src="/assets/js/dark_mode.js"></script> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script src="/assets/js/distillpub/template.v2.js"></script> <script src="/assets/js/distillpub/transforms.v2.js"></script> <script src="/assets/js/distillpub/overrides.js"></script> </head> <body> <d-front-matter> <script async type="text/json">{
      "title": "IV. ASSISTED TELEOPERATION",
      "description": "",
      "published": "",
      "authors": [
        
      ],
      "katex": {
        "delimiters": [
          {
            "left": "$",
            "right": "$",
            "display": false
          },
          {
            "left": "$$",
            "right": "$$",
            "display": true
          }
        ]
      }
    }</script> </d-front-matter> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-normal" href="/">Humanoid Teleoperation</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">home</a> </li> <li class="nav-item "> <a class="nav-link" href="/arXiv/">arXiv</a> </li> <li class="nav-item "> <a class="nav-link" href="/news/">news</a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">sections</a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item" href="/1-introduction/">I. INTRODUCTION</a> <div class="dropdown-divider"></div> <a class="dropdown-item" href="/2-teleop-sys-devices/">II. TELEOPERATION SYSTEM &amp; DEVICES</a> <div class="dropdown-divider"></div> <a class="dropdown-item" href="/3-retargeting-control/">III. HUMANOID ROBOT RETARGETING &amp; CONTROL</a> <div class="dropdown-divider"></div> <a class="dropdown-item" href="/4-assisted-teleop/">IV. ASSISTED TELEOPERATION</a> <div class="dropdown-divider"></div> <a class="dropdown-item" href="/5-communication/">V. COMMUNICATION CHANNEL</a> <div class="dropdown-divider"></div> <a class="dropdown-item" href="/6-design-evaluation/">VI. DESIGN &amp; EVALUATION OF HUMANOID <br> TELEOPERATION SYSTEM</a> <div class="dropdown-divider"></div> <a class="dropdown-item" href="/7-applications/">VII. APPLICATIONS &amp; PERSPECTIVES</a> </div> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> </header> <div class="post distill"> <d-title> <h1>IV. ASSISTED TELEOPERATION</h1> <p></p> </d-title> <d-byline></d-byline> <d-article> <d-contents> <nav class="l-text figcaption"> <h3>Contents</h3> <div><a href="#a-shared-control">A. Shared Control</a></div> <div><a href="#b-supervised-and-safeguarded-teleoperation">B. Supervised and Safeguarded Teleoperation</a></div> <div><a href="#c-bilateral-teleoperation">C. Bilateral Teleoperation</a></div> <ul> <li><a href="#1-upper-body-bilateral-teleoperation">1) Upper-body bilateral teleoperation</a></li> <li><a href="#2-whole-body-bilateral-teleoperation">2) Whole-body bilateral teleoperation</a></li> </ul> <div><a href="#d-impedance-control">D. Impedance Control</a></div> </nav> </d-contents> <p>In many teleoperation scenarios, controlling the robot as explained in the previous section, is not the only viable solution. In fact, many tasks can achieve higher performances by sharing the autonomy among the human and robot. This section provides more details about these assisted teleoperation strategies.</p> <h2 id="a-shared-control">A. Shared Control</h2> <p>Delegating robot’s full control to the human operator’s experience can often limit the efficiency of the teleoperation, resulting in clunky motions, failures, or numerous attempts before being able to accomplish a given task. This applies particularly to humanoid robots where the operator has to control many aspects at once via teleoperation (e.g., the pose of both hands, the feet location, balance) and can fail very easily without significant robot autonomy being used simultaneously. In shared-control teleoperation, some robot autonomy is used to assist the user in accomplishing the desired task, potentially making teleoperation easier and more seamless. Generally, the operator’s input is modified according to specific metrics by sharing the control authority between the robot and the operator to enhance performance or safety <d-cite key="dragan2013"></d-cite>. For example, in <d-cite key="rakita2019"></d-cite>, Rakita <em>et al.</em> teleoperated the upper-body of a humanoid using a shared-control approach, providing on-the-fly assistance to help the user complete tasks more easily, enhancing the end-effectors control while performing bi-manipulation of objects. Similarly, in <d-cite key="rahal2019"></d-cite>, Rahal <em>et al.</em> designed a shared control approach to assist the human operator by enforcing different nonholonomic-like constraints representative of the cutting kinematics. In other shared-control approaches, the user provides an input $\bf{u}$, which enables the robot to predict human intent, and assist her/him in the task by adjusting the motion or by executing a pre-optimized version of that motion <d-cite key="dragan2013"></d-cite>. Then, a blending policy arbitrates the user input $\bf{u}$ and the enhanced robot motion $\bf{r}$, determining the final reference: \begin{equation} \bf{u^*} = (1-\alpha)\bf{u}+\alpha\bf{r}, \label{eq:sharedcontrol} \end{equation} where $\alpha$ can be any scalar function. A common choice is the confidence in the prediction of the user intent: \begin{equation} \alpha = max(0, 1 - d/D), \label{eq:alpha} \end{equation} where $d$ the distance to the goal and $D$ some threshold past which the confidence is 0. In this case the closer the robot gets to a predicted goal, the more likely that this goal is the correct one, and the input $\bf{r}$ is preferred over $\bf{u}$. The prediction of the user intent has also been successfully used to provide haptic guidance through a master device to teleoperate a robot manipulator <d-cite key="Ly2021"></d-cite>, and could be applied to humanoid robots by using exoskeletons as input devices. The haptic information can also be used to enhance the user’s comfort during teleoperation <d-cite key="Rahal2020"></d-cite>.</p> <h2 id="b-supervised-and-safeguarded-teleoperation">B. Supervised and Safeguarded Teleoperation</h2> <p>When full robot autonomy is available for a given task, the operator can simply act as a supervisor. By monitoring the robot, the operator can then identify and react to unexpected problems and intervene in a timely manner by controlling the robot directly to handle “uncovered” situations. This was a common approach in the DRC, where team operators could guide the robot to achieve complex tasks through failure when needed <d-cite key="johnson2017team"></d-cite>. Similarly, in <d-cite key="dylan2013"></d-cite>, the user monitored multiple robots interacting with passersby in a shopping mall. The robots performed their own speech, gesture, and motion planning autonomously, and the role of the human was only to provide occasional sensor inputs. In rare cases, an operator had to control the robot directly to handle unexpected questions from a customer or to re-plan the robot’s path to avoid unmodeled obstacles.</p> <p>A mirrored approach can also be adopted when teleoperating robots. For example, in <d-cite key="fong2001"></d-cite>, the operators shared control with a safeguarding system onboard the robot. In benign situations, the operator had full control of the vehicle’s motion, while in hazardous situations, the safeguarder modified or overrode the operator’s commands to maintain safety. The safeguarder, therefore, exhibits many characteristics of autonomous systems, such as perception and command generation. In <d-cite key="fong2001"></d-cite>, the safeguarder not only had the function of preventing collision and rollover but also monitoring the system’s health (e.g., vehicle power, motor stall). A similar approach could be used for humanoid robots to prevent them from falling or reaching singular configurations while being operated by the user.</p> <h2 id="c-bilateral-teleoperation">C. Bilateral Teleoperation</h2> <p>Bilateral teleoperation techniques have been widely used in the literature for robot manipulators. In this approach, not only the robot receives kinodynamic references from the human, but the operator also receives kinesthetic feedback (force, pressure, vibration, etc) from the robot. This feedback informs the operator about the robot’s performance reproducing the commanded motion or about external disturbances applied to the machine. The approaches described next focus on teleoperating the upper- or whole-body, which in the latter case couples altogether the human operator and the robot at upper- and lower-body levels.</p> <h3 id="1-upper-body-bilateral-teleoperation">1) Upper-body bilateral teleoperation</h3> <p>A simpler strategy that has been adopted on humanoid robots consists in teleoperating the upper-body in a bilateral fashion, while using a separate balancing controller on the lower-body to regulate balance <d-cite key="brygo2014a,peer2008"></d-cite>. To control the upper limbs of the HRP-2, Peer <em>et al.</em> <d-cite key="peer2008"></d-cite> adopted a common control scheme for position-controlled robots: the <em>admittance</em> controller. Such controllers define the reference through the differential equation of a virtual mass-spring-damper system. Under time delay, the parameters of the controller should be selected appropriately to guarantee stability of the overall teleoperation system, as done in <d-cite key="evrard2009"></d-cite> while teleoperating the HRP-2 located in Tsukuba (Japan) from Munich (Germany).</p> <h3 id="2-whole-body-bilateral-teleoperation">2) Whole-body bilateral teleoperation</h3> <p>An extension of the conventional idea of bilateral teleoperation is starting to be investigated to dynamically couple human and robot at a whole-body level <d-cite key="ramos2018"></d-cite>. This strategy consists of mapping the whole-body kinematic (joints position, velocitiy, etc) and dynamic (contact forces, joint torques, etc) references from humans to robots, while providing the operator with feedback regarding the robot’s whole-body dynamics, as shown in Fig. 5. However, the naturally unstable dynamics of humanoid robots poses an additional challenge to the whole-body teleoperation: the robot must balance while reproducing human movement.</p> <p>The strategies for whole-body bilateral teleoperation utilize kinesthetic feedback to inform the operator about the robot’s dynamics and stability in real-time. The strategy usually focuses on the CoM dynamics, and other condensed information about the robot. For instance, the cable driven feedback interface in <d-cite key="peternel2013"></d-cite> exerts forces on the demonstrator’s waist corresponding to the state of the robot’s CoM. This feedback allows the human to teach the robot how to compliantly interact with the environment. In <d-cite key="Wang2015"></d-cite>, the feedback force applied to the human’s torso is proportional to how close the robot is from tipping over. This is estimated by considering the distance between the robot’s CoP and the edge of the support polygon. The closer the robot is from tipping over in one direction, the larger the feedback force applied to the operator in the opposite direction. A similar strategy is used in <d-cite key="brygo2014b"></d-cite> by providing discrete vibration levels to the operator using a belt with vibrotactile feedback. In <d-cite key="ishiguro2020bilateral"></d-cite>, the force feedback device TABLIS, a powered exoskeleton, applies forces to the operator’s feet to indicate that the robot is stepping onto an obstacle. This enables the operator to control the robot to navigate over objects. Finally, in <d-cite key="ramos2019dynamic"></d-cite> the force feedback is utilized to dynamically synchronize human and machine. The force feedback generates drag (negative feedback) if the robot cannot keep up with the operator’s movement, or it speeds up human motion (positive feedback) if the robot moves faster than the operator. The high-level expression for the force feedback is given by: \begin{equation} {\bf{f}_{fb}} = {k_H} [ ( {\dot{\bf{x}}’_R} - {\dot{\bf{x}}’_H} ) + {\bf{f}’_e} ], \end{equation} where \({\dot{\bf{x}}'_i}\) is the dimensionless CoM velocity of the human ($H$) and robot ($R$) <d-cite key="pratt2006"></d-cite>, \({\bf{f}'_{e}}\) is dimensionless external force vector applied to the robot, and \({k_H}\) is a scaling factor proportional to the operator’s size and body mass. This strategy enables human and robot to dynamically take simultaneous steps.</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/paper/Bilateral%20teleoperation-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/paper/Bilateral%20teleoperation-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/paper/Bilateral%20teleoperation-1400.webp"></source> <img src="/assets/img/paper/Bilateral%20teleoperation.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="control-diagram" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Fig. 5: General concept for whole-body bilateral teleoperation. The robot WBC computes joint torques $\tau_{j}$ using the reference interaction forces $F_H$ from the operator and the error $e$ between the human state $X_H$ and the robot state $X_R$. The external contact forces $F_k$ applied to the robot create a net wrench $W_{ext}$, which is used by the human-machine interface (HMI) to compute a proportional kinesthetic feedback $F_{fb}$ to the operator. </div> <p>In general, during whole-body bilateral teleoperation, the kinesthetic feedback provided to the operator is proportional to some kinematic or dynamic discrepancy between human and robot with respect to the task at hand and/or the balance regulation. The assisted teleoperation principle arises from the fact that the robot must prioritize between following the human motion command to perform a task and maintain its own bipedal stability. Some strategies shift the balancing authority to the robot’s autonomous controller. This means that the robot is responsible for predicting if a given command will jeopardize stability and deciding the best course of action to override the motion. For instance, in <d-cite key="ishiguro2018"></d-cite>, the robot’s controller uses stability considerations from the LIP model to modify the CoM trajectory commanded by the human, preventing the operator from destabilizing the robot. This represents a more conservative approach that guarantees stability of the movement of the robot, but prevents the operator from exploring motions that would go beyond the boundaries of the stability metric employed. In contrast, other approaches, such as <d-cite key="Ramos_Humanoids2015"></d-cite>, rely on the human operator to actively regulate the robot’s balance. In this sense, the robot follows the human’s movement with only minor regulation from the robot’s autonomous controller; then, the operator must perceive the robot’s destabilization through the kinesthetic feedback and mitigate it by adapting the commanded movement. Although riskier, this strategy frees the operator from abiding to the boundaries of predefined stability metrics, which are challenging to be mathematically defined in the context of legged robots. The goal of this approach is to eventually allow the operator to learn how to cope with the robot’s dynamics and to create new motions on the fly.</p> <h2 id="d-impedance-control">D. Impedance Control</h2> <p>A similar concept to admittance control can be employed in non-bilateral systems to provide the robot the ability to dexterously interact with the remote environment. In <d-cite key="brygo2014a"></d-cite>, Brygo <em>et al.</em> implement an autonomous <em>impedance</em> controller that regulates the robot’s joints stiffness and damping according to the manipulation loading conditions. Also in this case a virtual mass-spring-damper system is employed, but the main difference between admittance control and impedance control is that the former controls motion after a force is measured, while the latter controls force after motion (or deviation from a set point) is measured <d-cite key="keemink2018"></d-cite>. In <d-cite key="brygo2014a"></d-cite>, the COMAN robot performs free-space motions with compliant limbs to ensure safe interactions during unforeseen collisions on the whole-arm. During the manipulation task, the controller stiffens the humanoid arm joints according to the the external force sensed at the end-effector, permitting to handle the task loads.</p> <p>Alternatively, the impedance profile can be sent to the robot through a BMI applied to the operator’s arm, using for example non-intrusive position and EMG measurements, technique also known as <em>tele-impedance</em> <d-cite key="ajoudani2012"></d-cite>.</p> </d-article> <d-appendix> <d-footnote-list></d-footnote-list> <d-citation-list></d-citation-list> </d-appendix> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2023 Humanoid Teleoperation . Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. </div> </footer> <d-bibliography src="/assets/bibliography/humanoid-teleoperation.bib"></d-bibliography> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> </body> </html>